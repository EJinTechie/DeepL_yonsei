{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-26T04:25:48.929866Z",
     "start_time": "2024-11-26T04:25:45.701769Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T04:25:48.960323Z",
     "start_time": "2024-11-26T04:25:48.945374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SpotifyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class SpotifyRankPredictor(nn.Module):\n",
    "    def __init__(self, num_categories):\n",
    "        super(SpotifyRankPredictor, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(8, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Linear(16, num_categories)  # 출력층이 1개에서 5개(카테고리 수)로 변경\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)  # Softmax 활성화 함수 추가하여 각 카테고리의 확률 출력\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return self.softmax(x)"
   ],
   "id": "bfeb3bf9ec46e9be",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T04:25:49.051533Z",
     "start_time": "2024-11-26T04:25:49.038576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_data(df):\n",
    "    X = df[['Danceability', 'Energy', 'Loudness', 'Speechiness',\n",
    "            'Acousticness', 'Liveness', 'Tempo', 'Duration (ms)']].values\n",
    "\n",
    "    feature_scaler = MinMaxScaler()\n",
    "    X_scaled = feature_scaler.fit_transform(X)\n",
    "\n",
    "    ranks = df['Highest Charting Position'].values\n",
    "\n",
    "    # 다섯개의 카테고리로 나눔\n",
    "    def rank_to_category(rank):\n",
    "        if rank <= 10:\n",
    "            return 0  # Top 10\n",
    "        elif rank <= 30:\n",
    "            return 1  # Top 11-30\n",
    "        elif rank <= 50:\n",
    "            return 2  # Top 31-50\n",
    "        elif rank <= 100:\n",
    "            return 3  # Top 51-100\n",
    "        else:\n",
    "            return 4  # Below 100\n",
    "\n",
    "    \n",
    "    y_categorical = np.array([rank_to_category(rank) for rank in ranks])\n",
    "\n",
    "    # One-hot encoding 적용\n",
    "    num_categories = 5\n",
    "    y_encoded = np.eye(num_categories)[y_categorical]\n",
    "\n",
    "    return X_scaled, y_encoded, num_categories"
   ],
   "id": "ec818e3d214c56b5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T04:25:49.081433Z",
     "start_time": "2024-11-26T04:25:49.068478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer,\n",
    "                num_epochs=100, patience=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)  # Classification 문제로 바뀌었기 때문에 이 부분 수정. 기존에는 y_batch(-1,1)여서 연속적인 값 예측시 사용하는 것\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                _, actual = torch.max(y_batch.data, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == actual).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    return train_losses, val_losses"
   ],
   "id": "a481aa6b9ffbe221",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T04:25:49.111346Z",
     "start_time": "2024-11-26T04:25:49.098377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_class_weights(y):\n",
    "    # y는 one-hot encoded 형태이므로 실제 클래스로 변환\n",
    "    y_classes = np.argmax(y, axis=1)\n",
    "\n",
    "    # 각 클래스별 샘플 수 계산\n",
    "    class_counts = np.bincount(y_classes)\n",
    "\n",
    "    # 가중치 계산: 전체 샘플 수 / (클래스 수 * 각 클래스의 샘플 수)\n",
    "    weights = len(y) / (len(class_counts) * class_counts)\n",
    "\n",
    "    return torch.FloatTensor(weights)"
   ],
   "id": "f3a17b6b538a0b43",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T04:25:51.174748Z",
     "start_time": "2024-11-26T04:25:49.127296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    df = pd.read_csv('spotify_dataset.csv')\n",
    "    X_scaled, y_encoded, num_categories = preprocess_data(df)\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X_scaled, y_encoded, test_size=0.2, random_state=42\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = SpotifyDataset(X_train, y_train)\n",
    "    val_dataset = SpotifyDataset(X_val, y_val)\n",
    "    test_dataset = SpotifyDataset(X_test, y_test)\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    class_weights = compute_class_weights(y_train)\n",
    "    print(\"Class weights:\", class_weights)\n",
    "\n",
    "    model = SpotifyRankPredictor(num_categories)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)  #CrossEntropy에서 가중치 적용\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0001)\n",
    "\n",
    "    train_losses, val_losses = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, actual = torch.max(y_batch.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == actual).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, actual = torch.max(y_batch.data, 1)\n",
    "            y_pred.extend(predicted.numpy())\n",
    "            y_true.extend(actual.numpy())\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "523e2a81871cdeda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([1.6298, 1.3223, 1.8540, 0.7718, 0.5571])\n",
      "Epoch [1/100], Train Loss: 1.6135, Val Loss: 1.4736, Val Accuracy: 13.24%\n",
      "Epoch [2/100], Train Loss: 1.6136, Val Loss: 1.4744, Val Accuracy: 15.07%\n",
      "Epoch [3/100], Train Loss: 1.6099, Val Loss: 1.4734, Val Accuracy: 15.07%\n",
      "Epoch [4/100], Train Loss: 1.6099, Val Loss: 1.4735, Val Accuracy: 15.98%\n",
      "Epoch [5/100], Train Loss: 1.6069, Val Loss: 1.4747, Val Accuracy: 17.35%\n",
      "Epoch [6/100], Train Loss: 1.6072, Val Loss: 1.4732, Val Accuracy: 15.98%\n",
      "Epoch [7/100], Train Loss: 1.6009, Val Loss: 1.4725, Val Accuracy: 15.53%\n",
      "Epoch [8/100], Train Loss: 1.5996, Val Loss: 1.4728, Val Accuracy: 15.53%\n",
      "Epoch [9/100], Train Loss: 1.5992, Val Loss: 1.4739, Val Accuracy: 15.98%\n",
      "Epoch [10/100], Train Loss: 1.5966, Val Loss: 1.4753, Val Accuracy: 15.53%\n",
      "Epoch [11/100], Train Loss: 1.5999, Val Loss: 1.4763, Val Accuracy: 15.53%\n",
      "Epoch [12/100], Train Loss: 1.5985, Val Loss: 1.4773, Val Accuracy: 17.81%\n",
      "Epoch [13/100], Train Loss: 1.5970, Val Loss: 1.4777, Val Accuracy: 16.89%\n",
      "Epoch [14/100], Train Loss: 1.5937, Val Loss: 1.4795, Val Accuracy: 14.61%\n",
      "Epoch [15/100], Train Loss: 1.5926, Val Loss: 1.4776, Val Accuracy: 16.44%\n",
      "Epoch [16/100], Train Loss: 1.5934, Val Loss: 1.4802, Val Accuracy: 16.44%\n",
      "Epoch [17/100], Train Loss: 1.5937, Val Loss: 1.4795, Val Accuracy: 16.44%\n",
      "Early stopping triggered\n",
      "Test Accuracy: 16.89%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 5  5  6  5  0]\n",
      " [11  4 13  3  0]\n",
      " [ 7  4  9  5  2]\n",
      " [12 10 13 13  3]\n",
      " [25 22 19 17  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이강민\\AppData\\Local\\Temp\\ipykernel_11216\\598819680.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
